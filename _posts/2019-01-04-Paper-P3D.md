---
layout: post
title:  "Paper | Pseudo-3D Residual Networks"
date:   2019-01-04 21:24:01 +0800
categories: ComputerVision
tag: Paper
---
<!--
 * @Description: 
 * @Author: Leesky
 * @Date: 2019-01-03 21:35:30
 * @LastEditors: Leesky
 * @LastEditTime: 2019-01-05 11:49:22
 -->

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>


* content
{:toc}


#### 摘要

- 深层的C3D计算量和所需内存非常巨大，一个可行的办法是重复 off-the-shelf 二维卷积网络来实现三维卷积，通过一个在空间域上的1×3×3卷积核加上一个在时间域上的3×1×1的卷积核
- 提出了一个基于 Residual 的 Pseudo-3D Residual Network，将上述两个二维卷积通过不同组合的方式作为以这个block添加到Residual Network中，在 Sports-1M上比3D CNN和frame-based 3D CNN分别强5.3%和1.8%



#### Pseudo 3D Block and P3D ResNet

- Residual Units

  - 每个Residual Unit可以用式子(1)表示，<br>
    $$
    ~~~~~~~~~~~~x_{t-1} = h(x_t)+F(x_t),~~~~~~~~(1)
    $$
    <br>
    其中$$x_t,~x_{t+1}$$表示第t个残差单元的输入和输出，$$h(x_t)=x_t$$是一个identity mapping，F是非线性残差公式，所以式子(1)可以表示为
    <br>
    $$
    ~~~~~~~~~~~~(I+F)·x_t = x_t+F·x_t~:=x_t+F(x_t)=x_{t+1},~~~(2)
    $$
    <br>
    其中$$F·x_t$$表示$$x_t$$在残差函数$$F$$之后的结果。

    ResNet的主要idea是通过shortcut连接学习加入残差函数和连接该单元的输入，而不是直接学习与该单元无联系的非线性函数。

- P3D Blocks design: 在此两个卷积核有三种组合方式，分别是串行，并行和串并行。

  - P3D-A: 先spatial后temporal，

    - $$
      (I + T · S) · x_t := x_t + T (S (x_t )) = x_{t+1}
      $$

  - P3D-B: 两个卷积核分别连接终输出，

    - $$
      (I + S + T) · x_t := x_t + S (x_t ) + T (x_t ) = x_{t+1} .
      $$

  - P3D-C: 属于A和B的结合体，先S，然后S分别连接output和T，T再连接output

    - $$
      (I + S + T · S) · x_t := x_t + S (x_t ) + T (S (x_t )) = x_{t+1} .
      $$

  - Bottleneck architecture

    - the basic 2D block is modiﬁed with a bottleneck design for reducing the computation complexity. The ﬁrst and last 1 × 1 convolutional layers are applied for reducing and restoring dimen- sions of input sample, respectively. Such bottleneck design makes the middle 3 × 3 convolutions as a bottleneck with smaller input and output dimensions.
    - we additionally place two 1 × 1 × 1 convolutions at both ends of the path, which are responsible for reducing and then increasing the dimensions.
    - residul子结构中的那三层卷积(卷积核大小分别是1\*1，3\*3，1\*1，第一个1\*1卷积用来缩减维度，这样3\*3卷积的计算量就会下降，最后一个卷积用来恢复维度)
- P3D ResNet

  - 一共有四种P3D ResNet，分别是基于P3D-ABC三种block和混合用所有这三种blocks的。
  - 参数：
    - ResNet-50 fine-tuned on UCF101 videos
    - BN Dropout 
    - calculate average prediction score
  - 混用的block：P3D-A -> P3D-B -> P3D-C

#### 结果比较

- 上图就完事了。